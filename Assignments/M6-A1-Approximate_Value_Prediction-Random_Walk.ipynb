{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1000-state Random Walk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- States are numbered form 1 to 1000, from left to right.\n",
    "- All episode begin near the center on state 500.\n",
    "- States 1 and 1000 are terminal states, and it fetches a reward of -1 and 1 on transitioning to them, respectively.\n",
    "- Policy:\n",
    "\t* Agent can transition from current state to one of 100 states in left or rights, all with equal probability. So there are 200 possible actions. At edges, if an action goes beyond 1 or 1000, then the agent instead transition to the terminal states.\n",
    "    \n",
    "<img src=\"images/M6A1-P1.png\" alt=\"M4A1-P3\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Callable, List, Tuple, Sequence\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "import plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class random_walk_envioronment(object):\n",
    "    def __init__(self, n_states : int = 1000):\n",
    "        '''\n",
    "        @params:\n",
    "        n_states     :  Number of states in the example\n",
    "        '''\n",
    "        self.n_states = n_states # states numbered from 0 to (n_states - 1)\n",
    "        self.cur_state = self.n_states//2\n",
    "    \n",
    "    def reset(self):\n",
    "        self.cur_state = self.n_states//2\n",
    "        return self.cur_state\n",
    "    \n",
    "    def step(self, action : int):\n",
    "        '''\n",
    "        @params:\n",
    "        action      : Action as an integer. Basically a non-zero value denoting the number of steps taken in left or right direction.\n",
    "        \n",
    "        @doc:\n",
    "        Takes an action in the MDP. And returns the next state, immediate reward, flag for episode termination\n",
    "        and additional info (none here).\n",
    "        '''\n",
    "        next_state = None\n",
    "        reward = 0\n",
    "        done = False\n",
    "        info = None\n",
    "        \n",
    "        next_state = self.cur_state + action\n",
    "        \n",
    "        if(next_state>= self.n_states):\n",
    "            next_state = self.n_states - 1\n",
    "        \n",
    "        if(next_state < 0):\n",
    "            next_state = 0\n",
    "            \n",
    "        if(next_state == self.n_states-1):\n",
    "            reward = 1\n",
    "            done = True\n",
    "            \n",
    "        if(next_state == 0):\n",
    "            reward = -1\n",
    "            done = True\n",
    "        self.cur_state = next_state\n",
    "            \n",
    "        return next_state, reward, done, info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Monte-Carlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/M6A1-P2.jpg\" alt=\"M4A1-P3\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gradient_monte_carlo_prediction(object):\n",
    "    def __init__(self, env : random_walk_envioronment, n_buckets : int = 10, \\\n",
    "                 alpha : float = 2 * 1e-5, n_episodes : int = 100000, \\\n",
    "                 gamma : float= 1, n_left_jumps : int = 100, n_right_jumps : int = 100) -> None:\n",
    "        self.env = env\n",
    "        self.n_buckets = n_buckets\n",
    "        self.alpha = alpha\n",
    "        self.n_episodes = n_episodes\n",
    "        self.gamma = gamma\n",
    "        self.n_left_jumps = n_left_jumps\n",
    "        self.n_right_jumps = n_right_jumps\n",
    "        self.weights = np.zeros(self.n_buckets)\n",
    "        self.possible_jumps = np.concatenate([np.linspace(-self.n_left_jumps,-1,self.n_left_jumps),\\\n",
    "                                             np.linspace(1,self.n_right_jumps,self.n_right_jumps)])\n",
    "        \n",
    "    \n",
    "    def get_state_representation(self, state : int) -> List:\n",
    "        '''\n",
    "        Given a state(value between 0 and self.n_states-1), it return the state representation (an array of size self.n_bucktes)\n",
    "        '''\n",
    "        bucket_size = np.ceil(self.env.n_states/self.n_buckets)\n",
    "        state_rep = np.zeros(self.n_buckets)\n",
    "        state_rep[int(state/bucket_size)] = 1\n",
    "        return state_rep\n",
    "        \n",
    "    def value_function(self, state : int) -> float:\n",
    "        '''\n",
    "        Linear function approximator is used as the value function. \n",
    "        Given some state(0 to self.n_states-1), it return the value of that state.\n",
    "        '''\n",
    "        \n",
    "        state_rep = self.get_state_representation(state)\n",
    "        return np.dot(self.weights, state_rep)\n",
    "        \n",
    "    \n",
    "    def policy(self, cur_state : int) -> int: \n",
    "        '''\n",
    "        One of the possible (self.n_left_jumps + self.n_right_jumps) is selected as action.\n",
    "        '''\n",
    "        action = np.random.choice(self.possible_jumps)\n",
    "        return action\n",
    "        \n",
    "    \n",
    "    def generate_episode(self, max_episode_len : int = 1000000):\n",
    "        '''\n",
    "        Returns one episode as list of (state, action, reward) tuples \n",
    "        '''\n",
    "        episode = []\n",
    "        state = self.env.reset()\n",
    "        for _ in range(max_episode_len):\n",
    "            action = self.policy(state)\n",
    "            new_state, reward, done, info = self.env.step(action)\n",
    "            episode.append((state, action, reward))\n",
    "            if done:\n",
    "                return episode\n",
    "            state = new_state\n",
    "        return episode\n",
    "    \n",
    "    def estimate_state_value_function(self) -> None: \n",
    "        '''\n",
    "        Updates weight to find the approximate value function for the given policy using Gradient Monte-Carlo \n",
    "        '''\n",
    "        for episode_number in range(self.n_episodes):\n",
    "            if((episode_number+1)%1000 ==0):\n",
    "                print(\"\\rEpisode {}/{}\".format(episode_number + 1, self.n_episodes), end = \"\")\n",
    "                sys.stdout.flush()\n",
    "            episode = self.generate_episode()\n",
    "            G = 0\n",
    "            for time_step in reversed(range(len(episode))):\n",
    "                state, action, reward = episode[time_step]\n",
    "                G = self.gamma * G + reward\n",
    "                target = G\n",
    "                self.weights = self.weights + self.alpha * (target - self.value_function(state)) * self.get_state_representation(state)\n",
    "        self.plot_value_function()\n",
    "        \n",
    "    \n",
    "    def compute_true_values(self):\n",
    "        '''\n",
    "        Computes true value function, for comparison.\n",
    "        '''\n",
    "        states = np.arange(self.env.n_states)\n",
    "        true_value = np.linspace(-1,1,self.env.n_states)\n",
    "        true_value[0] = true_value[-1] = 0\n",
    "        actions = self.possible_jumps\n",
    "        for i in range(10000):\n",
    "            max_diff = 0\n",
    "            for state in states:\n",
    "                if(state == 0 or state == self.env.n_states-1):\n",
    "                    continue\n",
    "                init_state_value = true_value[state]\n",
    "                true_value[state] = 0\n",
    "                for action in actions:\n",
    "                    next_state = state + action\n",
    "                    next_state = min(next_state, self.env.n_states-1)\n",
    "                    next_state = max(next_state,0)\n",
    "                    reward = 0 \n",
    "                    if(next_state == self.env.n_states-1):\n",
    "                        reward = 1\n",
    "                    if(next_state == 0):\n",
    "                        reward = -1\n",
    "                    true_value[state] += ((1.0/(self.n_left_jumps + self.n_right_jumps)) * (reward + self.gamma * true_value[int(next_state)]))\n",
    "                max_diff = max(max_diff,abs(init_state_value - true_value[state]))\n",
    "            if(max_diff < 0.001):\n",
    "                break\n",
    "        return np.array(true_value)\n",
    "        \n",
    "    def plot_value_function(self):\n",
    "        '''\n",
    "        Plots the value function\n",
    "        '''\n",
    "        states = np.arange(self.env.n_states)[1:-1]\n",
    "        values = [self.value_function(state) for state in states]\n",
    "        true_values = self.compute_true_values()[1:-1]\n",
    "        fig, ax = plt.subplots()\n",
    "        plt.plot(states,values, label = 'Gradient Monte carlo')\n",
    "        plt.plot(states,true_values, label = 'True value function')\n",
    "        plt.ylabel('Value scale')\n",
    "        plt.xlabel('State')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100000/100000"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = random_walk_envioronment()\n",
    "gradient_monte_carlo_agent = gradient_monte_carlo_prediction(env, n_episodes=100000)\n",
    "# gradient_monte_carlo_agent.get_state_representation(500)\n",
    "gradient_monte_carlo_agent.estimate_state_value_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semi-gradient TD(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/M6A1-P3.jpg\" alt=\"M4A1-P3\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class semi_gradient_td_prediction(object):\n",
    "    def __init__(self, env : random_walk_envioronment, n_buckets : int = 10, \\\n",
    "                 alpha : float = 2 * 1e-5, n_episodes : int = 100000, \\\n",
    "                 gamma : float= 1, n_left_jumps : int = 100, n_right_jumps : int =100) -> None:\n",
    "        \n",
    "        '''\n",
    "        Implement this.\n",
    "        '''\n",
    "    \n",
    "    def get_state_representation(self, state : int) -> List:\n",
    "        '''\n",
    "        Given a state(value between 0 and self.n_states-1), it return the state representation (an array of size self.n_bucktes)\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        Implement this.\n",
    "        '''\n",
    "        \n",
    "    def value_function(self, state : int) -> float:\n",
    "        '''\n",
    "        Linear function approximator is used as the value function. \n",
    "        Given some state(0 to self.n_states-1), it return the value of that state.\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        Implement this.\n",
    "        '''\n",
    "    \n",
    "    def policy(self, cur_state : int) -> int:\n",
    "        '''\n",
    "        One of the possible (self.n_left_jumps + self.n_right_jumps) is selected as action.\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        Implement this.\n",
    "        '''\n",
    "    \n",
    "    def estimate_state_value_function(self) -> None:  \n",
    "        '''\n",
    "        Updates weight to find the approximate value function for the given policy using semi-gradient TD(0). \n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        Implement this.\n",
    "        '''\n",
    "        \n",
    "    def compute_true_values(self):\n",
    "        '''\n",
    "        Computes true value function, for comparison.\n",
    "        '''\n",
    "        states = np.arange(self.env.n_states)\n",
    "        true_value = np.linspace(-1,1,self.env.n_states)\n",
    "        true_value[0] = true_value[-1] = 0\n",
    "        actions = self.possible_jumps\n",
    "        for i in range(10000):\n",
    "            max_diff = 0\n",
    "            for state in states:\n",
    "                if(state == 0 or state == self.env.n_states-1):\n",
    "                    continue\n",
    "                init_state_value = true_value[state]\n",
    "                true_value[state] = 0\n",
    "                for action in actions:\n",
    "                    next_state = state + action\n",
    "                    next_state = min(next_state, self.env.n_states-1)\n",
    "                    next_state = max(next_state,0)\n",
    "                    reward = 0 \n",
    "                    if(next_state == self.env.n_states-1):\n",
    "                        reward = 1\n",
    "                    if(next_state == 0):\n",
    "                        reward = -1\n",
    "                    true_value[state] += ((1.0/(self.n_left_jumps + self.n_right_jumps)) * (reward + self.gamma * true_value[int(next_state)]))\n",
    "                max_diff = max(max_diff,abs(init_state_value - true_value[state]))\n",
    "            if(max_diff < 0.001):\n",
    "                break\n",
    "        return np.array(true_value)\n",
    "        \n",
    "    def plot_value_function(self):\n",
    "        '''\n",
    "        Plots the value function.\n",
    "        '''\n",
    "        states = np.arange(self.env.n_states)[1:-1]\n",
    "        values = [self.value_function(state) for state in states]\n",
    "        true_values = self.compute_true_values()[1:-1]\n",
    "        fig, ax = plt.subplots()\n",
    "        plt.plot(states,values, label = 'Semi-gradient TD')\n",
    "        plt.plot(states,true_values, label = 'True value function')\n",
    "        plt.ylabel('Value scale')\n",
    "        plt.xlabel('State')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = random_walk_envioronment()\n",
    "semi_gradient_td_agent = semi_gradient_td_prediction(env, alpha=0.001)\n",
    "semi_gradient_td_agent.estimate_state_value_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Monte-Carlo with tile coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gradient_monte_carlo_prediction_with_tile_coding(object):\n",
    "    def __init__(self, env : random_walk_envioronment, n_tilings : int = 50, \\\n",
    "                 n_tiles : int = 5, offset : int = 4, alpha : float = 2 * 1e-5, n_episodes : int = 100000, \\\n",
    "                 gamma : float= 1, n_left_jumps : int = 100, n_right_jumps : int =100) -> None:\n",
    "        \n",
    "        '''\n",
    "        Implement this.\n",
    "        '''\n",
    "        \n",
    "        \n",
    "    def get_all_representation(self) -> dict:\n",
    "        '''\n",
    "        Returns state representation of each state, as a dictionary.\n",
    "        Tile coding is used to get the sttae representation. \n",
    "        Number of tiles in each tiling will be one more than what is passed as parameter in the constructor. This is to account for the offset.\n",
    "        Size of state reprsentation array of one state = (self.n_tiles + 1) * self.n_tilings\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        Implement this.\n",
    "        '''\n",
    "        \n",
    "    def value_function(self, state : int) -> float:\n",
    "        '''\n",
    "        Linear function approximator is used as the value function. \n",
    "        Given some state(0 to self.n_states-1), it return the value of that state.\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        Implement this.\n",
    "        '''\n",
    "    \n",
    "    def policy(self, cur_state : int) -> int:\n",
    "        '''\n",
    "        Updates weight to find the approximate value function for the given policy using semi-gradient TD(0). \n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        Implement this.\n",
    "        '''\n",
    "    \n",
    "    def generate_episode(self, max_episode_len : int = 1000000):\n",
    "        '''\n",
    "        Returns one episode as list of (state, action, reward) tuples \n",
    "        '''\n",
    "        episode = []\n",
    "        state = self.env.reset()\n",
    "        for _ in range(max_episode_len):\n",
    "            action = self.policy(state)\n",
    "            new_state, reward, done, info = self.env.step(action)\n",
    "            episode.append((state, action, reward))\n",
    "            if done:\n",
    "                return episode\n",
    "            state = new_state\n",
    "        return episode\n",
    "    \n",
    "    def estimate_state_value_function(self) -> None:  \n",
    "        '''\n",
    "        Updates weight to find the approximate value function for the given policy using gradient monte carlo with tile coding. \n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        Implement this.\n",
    "        '''\n",
    "    \n",
    "    def compute_true_values(self):\n",
    "        '''\n",
    "        Computes true value function, for comparison.\n",
    "        '''\n",
    "        states = np.arange(self.env.n_states)\n",
    "        true_value = np.linspace(-1,1,self.env.n_states)\n",
    "        true_value[0] = true_value[-1] = 0\n",
    "        actions = self.possible_jumps\n",
    "        for i in range(10000):\n",
    "            max_diff = 0\n",
    "            for state in states:\n",
    "                if(state == 0 or state == self.env.n_states-1):\n",
    "                    continue\n",
    "                init_state_value = true_value[state]\n",
    "                true_value[state] = 0\n",
    "                for action in actions:\n",
    "                    next_state = state + action\n",
    "                    next_state = min(next_state, self.env.n_states-1)\n",
    "                    next_state = max(next_state,0)\n",
    "                    reward = 0 \n",
    "                    if(next_state == self.env.n_states-1):\n",
    "                        reward = 1\n",
    "                    if(next_state == 0):\n",
    "                        reward = -1\n",
    "                    true_value[state] += ((1.0/(self.n_left_jumps + self.n_right_jumps)) * (reward + self.gamma * true_value[int(next_state)]))\n",
    "                max_diff = max(max_diff,abs(init_state_value - true_value[state]))\n",
    "            if(max_diff < 0.001):\n",
    "                break\n",
    "        return np.array(true_value)\n",
    "        \n",
    "    def plot_value_function(self):\n",
    "        '''\n",
    "        Plots the value function.\n",
    "        '''\n",
    "        states = np.arange(self.env.n_states)[1:-1]\n",
    "        values = [self.value_function(state) for state in states]\n",
    "        true_values = self.compute_true_values()[1:-1]\n",
    "        fig, ax = plt.subplots()\n",
    "        plt.plot(states,values, label = 'Gradient MC with tile coding')\n",
    "        plt.plot(states,true_values, label = 'True value function')\n",
    "        plt.ylabel('Value scale')\n",
    "        plt.xlabel('State')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = random_walk_envioronment()\n",
    "gradient_mc_prediction_tile_coding_agent = gradient_monte_carlo_prediction_with_tile_coding(env, alpha=0.0002/50)\n",
    "gradient_mc_prediction_tile_coding_agent.estimate_state_value_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
